{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1OUh-f6MlSX-7ijt1FzDf-DXtpL1z_QQ3","timestamp":1705727942315}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"AHbx92NbH9zy"},"source":["Author: ProtonX Team\n","\n","Website: https://protonx.ai/"]},{"cell_type":"markdown","metadata":{"id":"MAffXtcGE3Dv"},"source":["## 1. Load dữ liệu"]},{"cell_type":"code","metadata":{"id":"q0RJ22Fzp6eq"},"source":["# Hướng dẫn về bộ dữ liệu này được thực hiện trong Lab Tokenizer\n","!wget --no-check-certificate https://storage.googleapis.com/learning-datasets/sarcasm.json -O /tmp/sarcasm.json\n","\n","import json\n","\n","with open(\"/tmp/sarcasm.json\", 'r') as f:\n","    datastore = json.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_XuCacUJW08q"},"source":["# https://storage.googleapis.com/learning-datasets/sarcasm.jsondatastore[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WBCiWl4w1e4z"},"source":["## 2. Tách từ"]},{"cell_type":"code","metadata":{"id":"Ekm_LeFrXXjm"},"source":["dataset = []\n","label_dataset = []\n","\n","for item in datastore:\n","    dataset.append(item[\"headline\"])\n","    label_dataset.append(item[\"is_sarcastic\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-NdzpS3b1085"},"source":["dataset[:10], label_dataset[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PUo1Y_sQ5n5J"},"source":["import numpy as np\n","\n","dataset = np.array(dataset)\n","label_dataset = np.array(label_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset"],"metadata":{"id":"5Sf-yQFq0t7H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nS_6Ts-JFMgm"},"source":["Chia dữ liệu"]},{"cell_type":"code","metadata":{"id":"hQGv73TT6H3B"},"source":["train_size = 0.8\n","size = int(len(dataset) * train_size)\n","\n","train_sentence = dataset[:size]\n","test_sentence = dataset[size:]\n","\n","train_label = label_dataset[:size]\n","test_label = label_dataset[size:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JOsaSVay-U9b"},"source":["len(train_sentence), len(test_sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TAUxW854-BjM"},"source":["### 2.1. Train_sequences"]},{"cell_type":"code","metadata":{"id":"Z2bpoHkI7F-n"},"source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_size"],"metadata":{"id":"PT1o_YxR0-Yh"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQAZv8KAGMLQ"},"source":["vocab_size = len(train_sentence)\n","embedding_size = 64\n","max_length = 25"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OaWlzdzn7SkI"},"source":["tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(train_sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.word_index"],"metadata":{"id":"Py5FCT051I_e"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BE1oMf2T7uP3"},"source":["train_sequences = tokenizer.texts_to_sequences(train_sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_sentence[1]"],"metadata":{"id":"WXg5JPxQ1ixt"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iB6pQfWyLlWQ"},"source":["train_sequences[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v5MUG7A88EeX"},"source":["padded_train_sequences = pad_sequences(train_sequences, maxlen=max_length, truncating=\"post\", padding=\"post\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_length"],"metadata":{"id":"-BP-sAjA1ud3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["padded_train_sequences[2:4]"],"metadata":{"id":"a4Vo2YM91sH3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["padded_train_sequences.shape"],"metadata":{"id":"I8ATrtlM2IMW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C-8y1Kiu99YU"},"source":["### 2.2. Test_sequences"]},{"cell_type":"code","metadata":{"id":"lHtup3rt9v9m"},"source":["test_sequences = tokenizer.texts_to_sequences(test_sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ns_zjlCa94LV"},"source":["padded_test_sequences = pad_sequences(test_sequences, maxlen=max_length, truncating=\"post\", padding=\"post\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TgGNUsms-L28"},"source":["padded_test_sequences.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b3zalGQWFcvA"},"source":["Custom Model LSTM"]},{"cell_type":"code","metadata":{"id":"0yDHd3mHJUfm"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pe0kdNIkFcmd"},"source":["Lập trình thuật toán cho một cell LSTM bao gồm các cổng đề điều chỉnh luồng thông tin:\n","- Cổng kiểm soát đầu vào\n","- Cổng kiểm soát số lượng dữ liệu giữ lại/quên đi\n","- Cổng kiểm soát dữ liệu đầu ra\n","\n","Code dưới đây kế thừa class Layer từ keras để override một số hàm cho mô hình cụ thể của chúng ta.\n","\n","[Xem thêm](https://www.tensorflow.org/tutorials/customization/custom_layers) cách sử dụng tại."]},{"cell_type":"code","metadata":{"id":"94V2xIB9Fd_y"},"source":["class LSTM(tf.keras.layers.Layer):\n","  def __init__(self, units, inp_shape):\n","    super(LSTM, self).__init__()\n","    self.units = units\n","    self.inp_shape = inp_shape\n","    self.W = self.add_weight(\"W\", shape=(4, self.units, self.inp_shape))\n","    self.U = self.add_weight(\"U\", shape=(4, self.units, self.units))\n","\n","\n","  def call(self, pre_layer, x):\n","    pre_h, pre_c = tf.unstack(pre_layer)\n","\n","    # Cổng kiểm soát đầu vào: Input Gate\n","\n","    i_t = tf.nn.sigmoid(tf.matmul(x, tf.transpose(self.W[0])) + tf.matmul( pre_h, tf.transpose(self.U[0])))\n","\n","    # Cổng kiểm soát số lượng dữ liệu giữ lại/quên đi: Forget Gate\n","    f_t = tf.nn.sigmoid(tf.matmul(x, tf.transpose(self.W[1])) + tf.matmul( pre_h, tf.transpose(self.U[1])))\n","\n","    # Cổng kiểm soát dữ liệu đầu ra: Output Gate\n","    o_t = tf.nn.sigmoid(tf.matmul(x, tf.transpose(self.W[2])) + tf.matmul( pre_h, tf.transpose(self.U[2])))\n","\n","    # Đây giống SimpleRNN và được coi là thông tin mới (bộ nhớ mới)\n","\n","    n_c_t = tf.nn.tanh(tf.matmul(x, tf.transpose(self.W[3])) + tf.matmul( pre_h, tf.transpose(self.U[3])))\n","\n","    # Kết hợp việc giữ lại thông tin + bổ sung thêm thông tin mới\n","\n","    c = tf.multiply(f_t, pre_c) + tf.multiply(i_t, n_c_t)\n","\n","    # Cho phép bao nhiêu thông tin thoát khỏi cell\n","\n","    h = tf.multiply(o_t, tf.nn.tanh(c))\n","\n","    return tf.stack([h, c])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LRAS7aIvF2T0"},"source":["## 3. Xây dựng mô hình"]},{"cell_type":"markdown","metadata":{"id":"8r5TbdjOGACN"},"source":["Thừa kế lại lớp Model của Keras để xây dựng mô hình riêng cho mình.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5j9dQO5WGNON"},"source":["Mô hình bao gồm\n","- Embedding để chuyển câu thành các vector với chiều `embedding_size`\n","- Sử dụng cell LSTM đã lập trình bên trên\n","- Sau đó đưa lịch sử `h` của LSTM qua mạng nơ ron đơn giản\n","\n","Qúa trình training bao gồm\n","- Đưa câu qua Embedding để lấy các vector\n","- Đưa `tuần tự` từng từ qua LSTM + (hidden_state và cell_state) lớp phía trước để thu được (hidden_state và cell_state) hiện tại\n","- Sử dụng hidden_state cuối cùng cho việc dự đoán"]},{"cell_type":"code","metadata":{"id":"BqbSAk99N-Cg"},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Odx6548tZA1U"},"source":["class Bidirectional(tf.keras.Model):\n","  def __init__(self, lstm1, lstm2):\n","    super(Bidirectional, self).__init__()\n","    self.lstm1 = lstm1\n","    self.lstm2 = lstm2\n","\n","  def call(self):\n","    # Left to right\n","\n","\n","    # Right to left\n","    pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wmcyKVDCLTO-","outputId":"23ba0f69-2393-480c-8c79-69f2ec808490","executionInfo":{"status":"ok","timestamp":1682686551409,"user_tz":-420,"elapsed":570,"user":{"displayName":"Ngọc Nguyễn","userId":"00234888355303416315"}}},"source":["class ProtonXRNN(tf.keras.Model):\n","  def __init__(self, units, embedding_size, vocab_size, input_length):\n","    super(ProtonXRNN, self).__init__()\n","    self.input_length = input_length\n","    self.units = units\n","\n","    # Embedding để chuyển từ thành vector\n","    self.embedding = tf.keras.layers.Embedding(\n","      vocab_size,\n","      embedding_size,\n","      input_length = input_length\n","    )\n","\n","    # Sử dụng cell LSTM đã lập trình bên trên\n","    self.lstm = LSTM(units, embedding_size)\n","\n","    # Sau đó đưa lịch sử h của LSTM qua mạng nơ ron đơn giản\n","    self.classfication_model = tf.keras.models.Sequential([\n","        tf.keras.layers.Dense(64, input_shape=(units,)),\n","        tf.keras.layers.Dense(1, activation='sigmoid')\n","    ])\n","\n","\n","  def call(self, sentence):\n","    \"\"\"\n","    Parameters:\n","    sentence:\n","      Dạng: Tensor\n","      Miêu tả: Câu\n","      Chiều: (batch_size, input_length)\n","    out:\n","      Dạng: Tensor\n","      Miêu tả: Đầu ra của mô hình dự đoán\n","      Chiều: (batch_size, 1)\n","    \"\"\"\n","\n","    batch_size = tf.shape(sentence)[0]\n","\n","    # Khởi tạo (hidden_state và context_state)\n","\n","    pre_layer = tf.stack([\n","      tf.zeros([batch_size, self.units]),\n","      tf.zeros([batch_size, self.units])\n","    ])\n","\n","    # Đưa câu qua Embedding để lấy các vector\n","    # embedded_sentence: (batch_size, input_length, embedding_size)\n","    embedded_sentence = self.embedding(sentence)\n","\n","    # Đưa tuần tự từng từ qua LSTM + (hidden_state và cell_state)\n","    # lớp phía trước để thu được (hidden_state và cell_state) hiện tại\n","    for i in range(self.input_length):\n","      # : đầu tiên: Lấy batch_size\n","      # i Vị trí từ\n","      # : cuối cùng: Lấy embedding.\n","      # (batch_size, embedding_size)\n","      word = embedded_sentence[:, i, :]\n","      pre_layer = self.lstm(pre_layer, word)\n","\n","\n","    h, _ = tf.unstack(pre_layer)\n","\n","    # Sử dụng hidden_state cuối cùng cho việc dự đoán\n","    return self.classfication_model(h)\n","\n","units = 128\n","embedding_size = 100\n","vocab_size = len(tokenizer.index_word) + 1\n","input_length = max_length\n","\n","# Khởi tạo đối tượng protonxrnn\n","protonxrnn = ProtonXRNN(units, embedding_size, vocab_size, input_length)\n","\n","\n","protonxrnn.compile(\n","    tf.keras.optimizers.Adam(0.0005) , loss='binary_crossentropy', metrics=['acc']\n",")\n","\n","# Tiến hành training\n","\n","protonxrnn(padded_train_sequences[10:13]).shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([3, 1])"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"BOJvJ7lvHvDM"},"source":["## 4. Tiến hành training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"47PJZq2gaR-P","outputId":"8343edab-508c-43db-b63f-c11d9c25af7c","executionInfo":{"status":"ok","timestamp":1682686767649,"user_tz":-420,"elapsed":214338,"user":{"displayName":"Ngọc Nguyễn","userId":"00234888355303416315"}}},"source":["protonxrnn.fit(padded_train_sequences, train_label, validation_data=(padded_test_sequences, test_label) ,batch_size=32, epochs=10)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","668/668 [==============================] - 44s 46ms/step - loss: 0.5625 - acc: 0.6732 - val_loss: 0.3688 - val_acc: 0.8368\n","Epoch 2/10\n","668/668 [==============================] - 17s 26ms/step - loss: 0.2638 - acc: 0.8937 - val_loss: 0.3363 - val_acc: 0.8516\n","Epoch 3/10\n","668/668 [==============================] - 18s 27ms/step - loss: 0.1471 - acc: 0.9479 - val_loss: 0.4384 - val_acc: 0.8499\n","Epoch 4/10\n","668/668 [==============================] - 17s 25ms/step - loss: 0.0877 - acc: 0.9708 - val_loss: 0.4103 - val_acc: 0.8450\n","Epoch 5/10\n","668/668 [==============================] - 17s 25ms/step - loss: 0.0571 - acc: 0.9804 - val_loss: 0.6194 - val_acc: 0.8366\n","Epoch 6/10\n","668/668 [==============================] - 17s 26ms/step - loss: 0.0376 - acc: 0.9879 - val_loss: 0.8931 - val_acc: 0.8278\n","Epoch 7/10\n","668/668 [==============================] - 17s 26ms/step - loss: 0.0243 - acc: 0.9929 - val_loss: 0.6982 - val_acc: 0.8340\n","Epoch 8/10\n","668/668 [==============================] - 18s 28ms/step - loss: 0.0168 - acc: 0.9953 - val_loss: 0.8313 - val_acc: 0.8233\n","Epoch 9/10\n","668/668 [==============================] - 17s 25ms/step - loss: 0.0189 - acc: 0.9950 - val_loss: 0.7761 - val_acc: 0.8291\n","Epoch 10/10\n","668/668 [==============================] - 17s 26ms/step - loss: 0.0153 - acc: 0.9956 - val_loss: 0.9564 - val_acc: 0.8227\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f4032d5e2c0>"]},"metadata":{},"execution_count":43}]}]}